{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prepare the environment\n",
    "\n",
    "Setup the `matplotlib` environment to look pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "# Show the plots inside the notebook.\n",
    "%matplotlib inline\n",
    "# Make the figures high-resolution.\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# Various font sizes.\n",
    "ticksFontSize=18\n",
    "labelsFontSizeSmall=20\n",
    "labelsFontSize=30\n",
    "titleFontSize=34\n",
    "legendFontSize=14\n",
    "matplotlib.rc('xtick', labelsize=ticksFontSize) \n",
    "matplotlib.rc('ytick', labelsize=ticksFontSize)\n",
    "# Colourmaps.\n",
    "cm=matplotlib.pyplot.cm.get_cmap('viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Compare the simulated outliers in the \"training time series\" of each orbital element to the actual outliers present in the TLEs. First, though, need to prepare the training time series of mean motion $n$, inclination $i$ and eccentricity $e$ (use a related quantity, perigee radius $r_p=(1-e)a$) on which the individual filters will be tested. The required steps are:\n",
    "\n",
    "1. Load TLE orbital elements.\n",
    "2. Filter out corrected TLEs.\n",
    "3. Run a moving window with a robust polynomial through the TLE orbital elements to smoothen the data.\n",
    "4. Generate the training time series = re-sample the orbital element from 3 at equally spaced epochs and simulate the outliers.\n",
    "5. Resample the time series from 3 at the actual TLE epochs and compute the magnitude of the outliers present in the TLEs.\n",
    "6. Compare the simulated outleirs from 4 to the actual ones from 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script controls\n",
    "\n",
    "Choose the whether to automatically save figures besides showing them, save the raw data, and which object to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SSC=13025 # Will work with this object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TLEs\n",
    "\n",
    "Do not parse the TLEs because that requires a parser function, which forms a part of the proprietary ESA code. Load already parsed elements extracted from the TLEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, numpy\n",
    "\n",
    "meanMotions=numpy.load('{}MeanMotions.npy'.format(SSC))\n",
    "eccentricities=numpy.load('{}eccentricities.npy'.format(SSC))\n",
    "inclinations=numpy.load('{}inclinations.npy'.format(SSC))\n",
    "epochsJD=numpy.load('{}epochsJD.npy'.format(SSC),)\n",
    "epochs=numpy.load('{}epochs.npy'.format(SSC))\n",
    "print(\"Read {} TLEs for {}.\".format(meanMotions.size,SSC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pre-process the TLEs\n",
    "\n",
    "Need to remove corrected TLEs from the time series, they will make resampling produce dodgy results.\n",
    "\n",
    "In the case of `13025` object, also remove the last TLE - it would be marked as an epoch outlier by `findNAndTOutliersAndSeqeunces` but we won't be running the filters here, so need to remove that TLE manually.\n",
    "\n",
    "The function to fitler corrected TLEs forms part of a proprietary code. However, its resuls for `13025` have been saved to `npy` files to allow the results to be reproduced. `outlierFlags` equal to 1 correspond to TLEs that are followed by another TLE published less than half an orbital period later, i.e. are believed to have been corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify the TLEs that have been corrected, i.e.\n",
    "# preceed the next one by less than 0.5 orbital period.\n",
    "# Filtering code not included.\n",
    "outlierFlags=numpy.load('{}outlierFlags.npy'.format(SSC))\n",
    "sequenceIDs=numpy.load('{}sequenceIDs.npy'.format(SSC))\n",
    "print(\"Found {} corrected TLEs.\".format(numpy.sum(\n",
    "      outlierFlags==1))) # TLEFiltering.OUTLIER_TYPES['corrected']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of the last TLE for 13025, it's an obvious epoch outlier.\n",
    "if SSC==13025:\n",
    "    print(\"The last TLE comes after a gap of \"\n",
    "          \"{:.4f} days after the previous one.\".format(epochsJD[-1]-\n",
    "                                                   epochsJD[-2]))\n",
    "    epochs=epochs[:-1]\n",
    "    epochsJD=epochsJD[:-1]\n",
    "    meanMotions=meanMotions[:-1]\n",
    "    eccentricities=eccentricities[:-1]\n",
    "    inclinations=inclinations[:-1]\n",
    "    outlierFlags=outlierFlags[:-1]\n",
    "    sequenceIDs=sequenceIDs[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the time series\n",
    "\n",
    "Need to first smoothen the original TLE time series, then prepare to resample them at desired epochs (equal 1 day intervals or original TLE epochs).\n",
    "\n",
    "## Smoothen the time series\n",
    "\n",
    "Use [LOWESS](https://en.wikipedia.org/wiki/Local_regression) non-parameteric regression to smoothen the time series of $n$, $e$ and $i$. This removes the noise and outliers.\n",
    "\n",
    "The LOWESS settings for every time series were choosen by comparing the values interpolated using a smoothed subset  of the TLEs to the complement of this subset. A test subset from the data was selected. The remainder, i.e. the training subset, was smoothed using LOWESS and interpolated on the epochs of the test subset. The discrepancies between the test subset and the interpolation was then minimised to yield the best LOWESS settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get rid of the corrected TLEs from the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs=numpy.delete(epochs,numpy.where(outlierFlags==1))\n",
    "epochsJD=numpy.delete(epochsJD,numpy.where(outlierFlags==1))\n",
    "meanMotions=numpy.delete(meanMotions,numpy.where(outlierFlags==1))\n",
    "eccentricities=numpy.delete(eccentricities,numpy.where(outlierFlags==1))\n",
    "inclinations=numpy.delete(inclinations,numpy.where(outlierFlags==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels\n",
    "assert statsmodels.__version__>='0.6.1'\n",
    "import scipy.interpolate\n",
    "assert scipy.__version__>='0.18.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use optimised LOWESS settings to smoothen time series of all orbital elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lwMeanMotions=sm.nonparametric.lowess(meanMotions,epochsJD,\n",
    "                                      frac=2.98e-3, # Fraction of data\n",
    "                                      # to use to smoothen each point.\n",
    "                                      it=0, # No. re-weightings.\n",
    "                                      delta=0, # Distance within which\n",
    "                                      # unweighted regression\n",
    "                                      # will be used.\n",
    "                                      missing='raise',is_sorted=True,\n",
    "                                      return_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lwInclinations=sm.nonparametric.lowess(inclinations,epochsJD,\n",
    "                                       frac=1.65e-2,it=0,delta=0,\n",
    "                                       missing='raise',\n",
    "                                       is_sorted=True,\n",
    "                                       return_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lwEccentricities=sm.nonparametric.lowess(eccentricities,epochsJD,\n",
    "                                         frac=5.75e-3,it=0,delta=0,\n",
    "                                         missing='raise',\n",
    "                                         is_sorted=True,\n",
    "                                         return_sorted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-sample the time series\n",
    "\n",
    "Prepare the interpolation of the time series of $n$, $e$ and $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "assert pd.__version__>='0.18.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cubic interpolation seems to work well. Linear has sharp gradient changes at the beinning and end of time gaps, and quadratic has large overshoots. Behaviour across the time gaps is even worse for kernel-based approaches from `scikit.learn`, which have an even larger overshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meanMotionInterp=scipy.interpolate.interp1d(epochsJD,lwMeanMotions,\n",
    "                                            kind='cubic',\n",
    "                                            bounds_error=True,\n",
    "                                            assume_sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eccentricityInterp=scipy.interpolate.interp1d(epochsJD,lwEccentricities,\n",
    "                                            kind='cubic',\n",
    "                                            bounds_error=True,\n",
    "                                            assume_sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inclinationInterp=scipy.interpolate.interp1d(epochsJD,lwInclinations,\n",
    "                                            kind='cubic',\n",
    "                                            bounds_error=True,\n",
    "                                            assume_sorted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare actual outliers to the simulated ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate \"training time series\"\n",
    "\n",
    "Resample the time series of $n$, $e$ and $i$ on a grid of equal, one-day time spacing. One-day time spacing is pretty reasonable for TLE update frequency. At the end of this, we'll have pristine time series into which we'll add outliers to have \"training time series\" of all orbital elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Epochs at which we'll resample the data to have pristine time series.\n",
    "# N.B. the epochs are the same for the training time series as well.\n",
    "epochsJDOneDay=numpy.arange(epochsJD[0],epochsJD[-1]+1e-3,1.0) # Span the original TLE time series epochs.\n",
    "epochsOneDay=pd.date_range(epochs[0],epochs[-1],freq='1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pristine time series w/o any outliers.\n",
    "meanMotionPristine=meanMotionInterp(epochsJDOneDay)\n",
    "eccentricityPristine=eccentricityInterp(epochsJDOneDay)\n",
    "inclinationPristine=inclinationInterp(epochsJDOneDay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add sequences to the mean motion time series, they're the cause of the \n",
    "need for false +ve and -ve trade-off. Put sequences in different $\\dot{n}$\n",
    "phases of the decay. Make them larger than largest outliers (10%).\n",
    "Use varying lengths of sequences to be robust (30, 40, 50, 60 TLEs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanMotionPristine[:30]*=0.8 # Arbitrary, at the time series start.\n",
    "meanMotionPristine[650:690]*=1.2 # 1 Oct 83\n",
    "meanMotionPristine[1077:1127]*=1.2 # 1 Dec 84\n",
    "meanMotionPristine[1685:1745]*=1.2 # 1 Aug 86\n",
    "meanMotionPristine[2385:2415]*=1.2 # 1 Jul 88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved outlier data, which have been chosen so as to include outliers in various phases of orbital decay, and to include different combinations of outliers (single, double consecutive etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiply pristine time series values by some factor, 0 for non-outliers.\n",
    "outlierMultipliers_n=numpy.loadtxt('{}NOutlierMultipliers.csv'.format(SSC))\n",
    "outlierMultipliers_e=numpy.loadtxt('{}EOutlierMultipliers.csv'.format(SSC))\n",
    "outlierMultipliers_i=numpy.loadtxt('{}IOutlierMultipliers.csv'.format(SSC))\n",
    "\n",
    "# Maximum size of the outliers relative to the pristine time series.\n",
    "maxSimulatedOM_n=0.1\n",
    "maxSimulatedOM_e=0.25\n",
    "maxSimulatedOM_i=0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add outliers into the pristine time series to generate training time series. Here only use the largest possible outlier magnitude. In the optimisation, a range of outlier magnitudes were used to ensure the optimisised filters would also identify small outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# outlierMultipliers != 0 give outleir direction (and size relative to other otuliers),\n",
    "# OM gives the size of the outliers relative to the pristine time series.\n",
    "meanMotionTraining=meanMotionPristine + maxSimulatedOM_n*outlierMultipliers_n*meanMotionPristine\n",
    "eccentricityTraining=eccentricityPristine +  maxSimulatedOM_e*outlierMultipliers_e*eccentricityPristine\n",
    "inclinationTraining=inclinationPristine + maxSimulatedOM_i*outlierMultipliers_i*inclinationPristine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the real outlier maginitude\n",
    "\n",
    "Find the differences between the smoothed time series and real TLEs - this is the magnitude of outliers that we have observed for this object, if we assume that the smoothed time series represents the actual time series of a given orbital element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, resample $n$, $e$ and $i$ at the TLE epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanMotionResampledAtTLEEpochs=meanMotionInterp(epochsJD)\n",
    "eccentricityResampledAtTLEEpochs=eccentricityInterp(epochsJD)\n",
    "inclinationResampledAtTLEEpochs=inclinationInterp(epochsJD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the largest outliers in the three orbital elements. Treat the smoothed time series as a reference, w.r.t. which we compute the outlier magnitudes, `OM`s. We simulate the outliers w.r.t. same reference to generate the \"training time series\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "realOM_n=numpy.abs((meanMotions-meanMotionResampledAtTLEEpochs)/meanMotionResampledAtTLEEpochs)\n",
    "realOM_e=numpy.abs((eccentricities-eccentricityResampledAtTLEEpochs)/eccentricityResampledAtTLEEpochs)\n",
    "realOM_i=numpy.abs((inclinations-inclinationResampledAtTLEEpochs)/inclinationResampledAtTLEEpochs)\n",
    "maxRealOM_n=max(realOM_n)\n",
    "maxRealOM_e=max(realOM_e)\n",
    "maxRealOM_i=max(realOM_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the simulated and real outliers\n",
    "\n",
    "Compare the magnitudes of the simulated and real outliers, and plot histograms of the outliers in every orbital element. Also plot the time series of $n$, $e$ and $i$ with the largest simulated outliers against the actual TLE time series of the given element and the pristine time series, which we treat as reference time series for every orbital element.\n",
    "\n",
    "Ratio of simulated to real outlier magnitudes greater than `1.0` signifies that we've simulated outliers greater than we've actually seen for this object. Ratios lower than `1.0` signify the opposite, i.e. that we haven't simulated outliers as big as we know happen for real objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the largest outliers in different elements.\n",
    "print('The largest n OM, simulated={:.4f}, real={:.4f},ratio={:.4f}.'.format(\n",
    "    maxSimulatedOM_n,maxRealOM_n,maxSimulatedOM_n/maxRealOM_n))\n",
    "print('The largest e OM, simulated={:.4f}, real={:.4f},ratio={:.4f}.'.format(\n",
    "    maxSimulatedOM_e,maxRealOM_e,maxSimulatedOM_e/maxRealOM_e))\n",
    "print('The largest i OM, simulated={:.4f}, real={:.4f},ratio={:.4f}.'.format(\n",
    "    maxSimulatedOM_i,maxRealOM_i,maxSimulatedOM_i/maxRealOM_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make histograms of the real OMs.\n",
    "fig,ax=matplotlib.pyplot.subplots(1,1,sharex=True,figsize=(14,8))\n",
    "ax.hist(realOM_n,100,color='indigo',histtype='step',density=True,cumulative=True,lw=3,label=r\"$n$\")\n",
    "ax.set_ylabel(r\"$No.\\ outliers$\",fontsize=labelsFontSize)\n",
    "ax.grid(linewidth=1)\n",
    "ax.legend(bbox_to_anchor=(0.5,1.1),loc='upper center',\n",
    "          prop={'size':legendFontSize},fancybox=True,shadow=True,ncol=3)\n",
    "ax.tick_params(axis='both',reset=False,which='both',length=5,width=1.5)\n",
    "ax.set_xlabel(r\"$Outliers\\ CDF$\", size=labelsFontSize)\n",
    "fig.show()\n",
    "\n",
    "fig,ax=matplotlib.pyplot.subplots(1,1,sharex=True,figsize=(14,8))\n",
    "ax.hist(realOM_e,100,color='crimson',histtype='step',density=True,cumulative=True,lw=3,label=r\"$e$\")\n",
    "ax.set_ylabel(r\"$Outliers\\ CDF$\",fontsize=labelsFontSize)\n",
    "ax.grid(linewidth=1)\n",
    "ax.legend(bbox_to_anchor=(0.5,1.1),loc='upper center',\n",
    "          prop={'size':legendFontSize},fancybox=True,shadow=True,ncol=3)\n",
    "ax.tick_params(axis='both',reset=False,which='both',length=5,width=1.5)\n",
    "ax.set_xlabel(r\"$Real\\ OM$\", size=labelsFontSize)\n",
    "fig.show()\n",
    "\n",
    "fig,ax=matplotlib.pyplot.subplots(1,1,sharex=True,figsize=(14,8))\n",
    "ax.hist(realOM_i,100,color='gold',histtype='step',density=True,cumulative=True,lw=3,label=r\"$i$\")\n",
    "ax.set_ylabel(r\"$Outliers\\ CDF$\",fontsize=labelsFontSize)\n",
    "ax.grid(linewidth=1)\n",
    "ax.legend(bbox_to_anchor=(0.5,1.1),loc='upper center',\n",
    "          prop={'size':legendFontSize},fancybox=True,shadow=True,ncol=3)\n",
    "ax.tick_params(axis='both',reset=False,which='both',length=5,width=1.5)\n",
    "ax.set_xlabel(r\"$Real\\ OM$\", size=labelsFontSize)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot mean motion time series.\n",
    "fig,ax=matplotlib.pyplot.subplots(1,1,sharex=True,figsize=(14,8))\n",
    "ax.scatter(epochs,meanMotions,color='indigo',marker='o',s=10,label=r\"$TLEs$\")\n",
    "ax.scatter(epochsOneDay,meanMotionTraining,color='crimson',\n",
    "           marker='x',s=10,label=r\"$Training$\")\n",
    "ax.plot(epochsOneDay,meanMotionPristine,ls='-',lw=2,c='gold',label=r'$Pristine$')\n",
    "ax.set_ylabel(r\"$n\\ (rev\\ day^{-1})$\",fontsize=labelsFontSize)\n",
    "ax.grid(linewidth=1)\n",
    "lower=min(meanMotions.min(),meanMotionTraining.min(),meanMotionPristine.min())\n",
    "upper=max(meanMotions.max(),meanMotionTraining.max(),meanMotionPristine.max())\n",
    "ax.set_yticks(numpy.linspace(numpy.floor(lower),numpy.ceil(upper),5) )\n",
    "ax.legend(bbox_to_anchor=(0.5,1.1),loc='upper center',\n",
    "          prop={'size':legendFontSize},fancybox=True,shadow=True,ncol=3)\n",
    "ax.tick_params(axis='both',reset=False,which='both',length=5,width=1.5)\n",
    "ax.set_xlabel(r\"$TLE\\ epoch\\ (UTC)$\", size=labelsFontSize)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot eccentricity time series.\n",
    "fig,ax=matplotlib.pyplot.subplots(1,1,sharex=True,figsize=(14,8))\n",
    "ax.scatter(epochs,eccentricities,color='indigo',marker='o',s=10,label=r\"$TLEs$\")\n",
    "ax.scatter(epochsOneDay,eccentricityTraining,color='crimson',\n",
    "           marker='x',s=10,label=r\"$Training$\")\n",
    "ax.plot(epochsOneDay,eccentricityPristine,ls='-',lw=2,c='gold',label=r'$Pristine$')\n",
    "ax.set_ylabel(r\"$e\\ (-)$\",fontsize=labelsFontSize)\n",
    "ax.grid(linewidth=1)\n",
    "lower=min(eccentricities.min(),eccentricityTraining.min(),eccentricityPristine.min())\n",
    "upper=max(eccentricities.max(),eccentricityTraining.max(),eccentricityPristine.max())\n",
    "ax.set_yticks(numpy.linspace(numpy.floor(lower),numpy.ceil(upper),5) )\n",
    "ax.legend(bbox_to_anchor=(0.5,1.1),loc='upper center',\n",
    "          prop={'size':legendFontSize},fancybox=True,shadow=True,ncol=3)\n",
    "ax.tick_params(axis='both',reset=False,which='both',length=5,width=1.5)\n",
    "ax.set_xlabel(r\"$TLE\\ epoch\\ (UTC)$\", size=labelsFontSize)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot inclination time series.\n",
    "fig,ax=matplotlib.pyplot.subplots(1,1,sharex=True,figsize=(14,8))\n",
    "ax.scatter(epochs,inclinations,color='indigo',marker='o',s=10,label=r\"$TLEs$\")\n",
    "ax.scatter(epochsOneDay,inclinationTraining,color='crimson',\n",
    "           marker='x',s=10,label=r\"$Training$\")\n",
    "ax.plot(epochsOneDay,inclinationPristine,ls='-',lw=2,c='gold',label=r'$Pristine$')\n",
    "ax.set_ylabel(r\"$i\\ (degrees)$\",fontsize=labelsFontSize)\n",
    "ax.grid(linewidth=1)\n",
    "lower=min(inclinations.min(),inclinationTraining.min(),inclinationPristine.min())\n",
    "upper=max(inclinations.max(),inclinationTraining.max(),inclinationPristine.max())\n",
    "ax.set_yticks(numpy.linspace(numpy.floor(lower),numpy.ceil(upper),5) )\n",
    "ax.legend(bbox_to_anchor=(0.5,1.1),loc='upper center',\n",
    "          prop={'size':legendFontSize},fancybox=True,shadow=True,ncol=3)\n",
    "ax.tick_params(axis='both',reset=False,which='both',length=5,width=1.5)\n",
    "ax.set_xlabel(r\"$TLE\\ epoch\\ (UTC)$\", size=labelsFontSize)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
